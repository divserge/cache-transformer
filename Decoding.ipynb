{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.contrib.lookup import MutableHashTable\n",
    "from tensor2tensor.layers import common_layers\n",
    "\n",
    "from tensor2tensor.models import transformer\n",
    "sys.path.append('/workspace/MT/tensor2tensor/tensor2tensor/models/')\n",
    "sys.path.append('/workspace/MT/tensor2tensor/tensor2tensor/utils/')\n",
    "\n",
    "from transformer_test import TransformerTest\n",
    "from transformer_cache import TransformerCache\n",
    "from tensor2tensor.data_generators import problem_hparams\n",
    "from tensor2tensor.data_generators import problem\n",
    "\n",
    "sys.path.append('/workspace/MT/t2t_data_generators/')\n",
    "\n",
    "from generator import ShadENRUOpusProblem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=3\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found vocab file: /workspace/MT/shad_nlp18_contextNMT/data_4prev/vocab_enru.src\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-26 14:33:45,615] Found vocab file: /workspace/MT/shad_nlp18_contextNMT/data_4prev/vocab_enru.src\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found vocab file: /workspace/MT/shad_nlp18_contextNMT/data_4prev/vocab_enru.dst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-26 14:33:45,907] Found vocab file: /workspace/MT/shad_nlp18_contextNMT/data_4prev/vocab_enru.dst\n"
     ]
    }
   ],
   "source": [
    "shad_problem = ShadENRUOpusProblem()\n",
    "\n",
    "data = shad_problem.generate_encoded_samples(\n",
    "    '/workspace/MT/shad_nlp18_contextNMT/data_4prev/',\n",
    "    '/workspace/MT/shad_nlp18_contextNMT/data_4prev/',\n",
    "    problem.DatasetSplit.TEST\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_input = True\n",
    "mode=tf.estimator.ModeKeys.EVAL\n",
    "\n",
    "hparams = transformer.transformer_base_single_gpu()\n",
    "hparams.data_dir =  '/workspace/MT/shad_nlp18_contextNMT/data_4prev//'\n",
    "p_hparams = shad_problem.get_hparams(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams.batch_size = 512\n",
    "hparams.use_cache = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Unsetting shared_embedding_and_softmax_weights.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-26 14:33:48,288] Unsetting shared_embedding_and_softmax_weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-26 14:33:48,290] Setting T2TModel mode to 'eval'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-26 14:33:48,291] Setting hparams.attention_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-26 14:33:48,292] Setting hparams.layer_prepostprocess_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-26 14:33:48,294] Setting hparams.dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-26 14:33:48,295] Setting hparams.relu_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-26 14:33:48,408] Setting hparams.symbol_dropout to 0.0\n"
     ]
    }
   ],
   "source": [
    "model = TransformerCache(hparams, mode, p_hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_true = {\n",
    "    \"inputs\": tf.placeholder(shape=[None, None, 1, 1], dtype=tf.int32, name=\"inputs\"),\n",
    "    \"targets\": tf.placeholder(shape=[None, None, 1, 1], dtype=tf.int32, name=\"inputs\"),\n",
    "    \"target_space_id\": tf.constant(1, dtype=tf.int32)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found vocab file: /workspace/MT/shad_nlp18_contextNMT/data_4prev/vocab_enru.src\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-26 14:34:03,300] Found vocab file: /workspace/MT/shad_nlp18_contextNMT/data_4prev/vocab_enru.src\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found vocab file: /workspace/MT/shad_nlp18_contextNMT/data_4prev/vocab_enru.dst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-26 14:34:03,703] Found vocab file: /workspace/MT/shad_nlp18_contextNMT/data_4prev/vocab_enru.dst\n"
     ]
    }
   ],
   "source": [
    "data = shad_problem.generate_encoded_samples(\n",
    "    '/workspace/MT/shad_nlp18_contextNMT/data_4prev/',\n",
    "    '/workspace/MT/shad_nlp18_contextNMT/data_4prev/',\n",
    "    problem.DatasetSplit.TEST\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_length = tf.placeholder(dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"transformer_cache/while/Identity:0\", shape=(), dtype=int32)\n",
      "KEK\n"
     ]
    }
   ],
   "source": [
    "fast_result = model._beam_decode(features_true, decode_length, beam_size=2, top_beams=1, alpha=1.0)[\"outputs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict = {\"/\".join([\"transformer\"] + var.name[:-2].split('/')[1:]) : var for var in tf.global_variables()[5:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(save_dict)\n",
    "ckpt = tf.train.get_checkpoint_state('/workspace/MT/train/transformer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /workspace/MT/train/transformer/model.ckpt-250000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-26 14:34:32,722] Restoring parameters from /workspace/MT/train/transformer/model.ckpt-250000\n"
     ]
    }
   ],
   "source": [
    "if ckpt and ckpt.model_checkpoint_path:\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "else:\n",
    "    print(\"...no checkpoint found...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_saver = tf.train.Saver(tf.global_variables()[2:4])\n",
    "new_ckpt = tf.train.get_checkpoint_state('/workspace/MT/train_cache_20/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.tools.inspect_checkpoint import print_tensors_in_checkpoint_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_name:  sentence_level_cache/m_weight\n",
      "[[ 0.07380127 -0.04234185  0.01600658 ..., -0.06169799 -0.04648288\n",
      "  -0.04955705]\n",
      " [ 0.03262606  0.01693438 -0.05247945 ..., -0.02262283 -0.01791717\n",
      "   0.02173471]\n",
      " [-0.00014766 -0.03526628  0.049478   ...,  0.06254897  0.01617665\n",
      "   0.01795316]\n",
      " ..., \n",
      " [-0.04530904  0.01187693  0.02088205 ..., -0.01862956  0.07036144\n",
      "  -0.01013484]\n",
      " [ 0.05326597 -0.02180931 -0.04270589 ..., -0.04181979 -0.0632555\n",
      "   0.02310421]\n",
      " [ 0.06577425  0.03144341 -0.0326293  ...,  0.04838184  0.04768109\n",
      "  -0.02183831]]\n",
      "tensor_name:  sentence_level_cache/s_weight\n",
      "[[-0.26558256 -0.04184648 -0.00348587 ..., -0.03543508 -0.02132302\n",
      "  -0.04346479]\n",
      " [-0.0355101  -0.08952183 -0.01517962 ..., -0.00255992  0.0009725\n",
      "  -0.00656878]\n",
      " [-0.03449194  0.00517168 -0.21918836 ..., -0.01575324 -0.03562221\n",
      "   0.01086152]\n",
      " ..., \n",
      " [-0.02436506 -0.02863154 -0.02006347 ...,  0.10057332 -0.00520056\n",
      "  -0.02264301]\n",
      " [-0.01808656 -0.01539315 -0.0196846  ...,  0.00678068  0.0188323\n",
      "  -0.01142946]\n",
      " [-0.00760054 -0.01035585  0.00179569 ..., -0.00779384 -0.01190156\n",
      "  -0.10218419]]\n"
     ]
    }
   ],
   "source": [
    "print_tensors_in_checkpoint_file(file_name=new_ckpt.model_checkpoint_path, tensor_name='',all_tensors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /workspace/MT/train_cache_20/transformer_cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-26 14:34:33,702] Restoring parameters from /workspace/MT/train_cache_20/transformer_cache\n"
     ]
    }
   ],
   "source": [
    "if new_ckpt and new_ckpt.model_checkpoint_path:\n",
    "    new_saver.restore(sess, new_ckpt.model_checkpoint_path)\n",
    "else:\n",
    "    print(\"...no checkpoint found...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders = shad_problem.feature_encoders('/workspace/MT/shad_nlp18_contextNMT/data_4prev/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import zip_longest\n",
    "\n",
    "def box_hpaulj(LoL):\n",
    "    return np.array(list(zip_longest(*LoL, fillvalue=0)), dtype=np.int32).T\n",
    "\n",
    "def batch_iterator(data, batch_size, context_size, n_steps=1000):\n",
    "    \n",
    "    for k in range(n_steps):\n",
    "        \n",
    "        batch_list_inp = [[] for _ in range(context_size)]\n",
    "        batch_list_targ = [[] for _ in range(context_size)]\n",
    "\n",
    "        for batch_i in range(batch_size):\n",
    "            for context_i, p in enumerate(data):\n",
    "                batch_list_inp[context_i].append(p['inputs'])\n",
    "                batch_list_targ[context_i].append(p['targets'])\n",
    "                if context_i == context_size - 1:\n",
    "                    break\n",
    "\n",
    "        for b_inp, b_out in zip(batch_list_inp, batch_list_targ):\n",
    "            yield {'inputs' : box_hpaulj(b_inp), 'targets' : box_hpaulj(b_out)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found vocab file: /workspace/MT/shad_nlp18_contextNMT/data_4prev/vocab_enru.src\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-26 14:34:57,688] Found vocab file: /workspace/MT/shad_nlp18_contextNMT/data_4prev/vocab_enru.src\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found vocab file: /workspace/MT/shad_nlp18_contextNMT/data_4prev/vocab_enru.dst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-26 14:34:57,920] Found vocab file: /workspace/MT/shad_nlp18_contextNMT/data_4prev/vocab_enru.dst\n"
     ]
    }
   ],
   "source": [
    "data = shad_problem.generate_encoded_samples(\n",
    "    '/workspace/MT/shad_nlp18_contextNMT/data_4prev/',\n",
    "    '/workspace/MT/shad_nlp18_contextNMT/data_4prev/',\n",
    "    problem.DatasetSplit.TEST,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "flusher = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in batch_iterator(data, hparams.batch_size, 5, n_steps=10000):\n",
    "    \n",
    "    inputs = it['inputs'].reshape((it['inputs'].shape[0], it['inputs'].shape[1], 1, 1))\n",
    "    targets = it['targets'].reshape((it['targets'].shape[0], it['targets'].shape[1], 1, 1))\n",
    "    kek = sess.run([fast_result], feed_dict={\n",
    "        features_true['inputs'] : inputs,\n",
    "        features_true['targets'] : targets,\n",
    "        decode_length : 25\n",
    "    })\n",
    "    \n",
    "    with open('/workspace/MT/transformer_cache20_pred_ru.dst', 'a', encoding='utf8') as file_pred:\n",
    "        with open('/workspace/MT/transformer_cache20_true_ru.dst', 'a', encoding='utf8') as file_true:\n",
    "            for seq_i in range(hparams.batch_size):\n",
    "                pred = encoders['targets'].decode(kek[0][seq_i][:-1])\n",
    "                true = encoders['targets'].decode(targets[seq_i][:-1].squeeze(1).squeeze(1))\n",
    "                print(''.join(pred.split('<EOS>')[0]), file=file_pred)\n",
    "                print(''.join(true.split('<EOS>')[0]), file=file_true)\n",
    "                \n",
    "    counter += 1\n",
    "    flusher += 1\n",
    "    \n",
    "    if flusher == 5:\n",
    "        sess.run(model.sentence_cache.Flush())\n",
    "        flusher = 0\n",
    "    \n",
    "    if counter == 60:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = [\n",
    "    'How do you choose the matrix columns?',\n",
    "    'You just choose the columns at random',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_inp = [encoders['inputs'].encode(t) for t in inp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[122, 39, 6, 1263, 8, 4670, 15341, 22026, 21995],\n",
       " [16, 44, 1263, 8, 15341, 63, 4573]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  122,    39,     6,  1263,     8,  4670, 15341, 22026, 21995]], dtype=int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box_hpaulj(fake_inp[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(model.sentence_cache.Flush())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "kek = sess.run([fast_result], feed_dict={\n",
    "        features_true['inputs'] : box_hpaulj(fake_inp[0:1]).reshape(1, -1, 1, 1),\n",
    "        features_true['targets'] : box_hpaulj(fake_inp[0:1]).reshape(1, -1, 1, 1),\n",
    "        decode_length : 25\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Как вы можете выбирать климатрицы матрицы?<EOS><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoders['targets'].decode(kek[0][0][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "kek = sess.run([fast_result], feed_dict={\n",
    "        features_true['inputs'] : box_hpaulj(fake_inp[1:2]).reshape(1, -1, 1, 1),\n",
    "        features_true['targets'] : box_hpaulj(fake_inp[0:1]).reshape(1, -1, 1, 1),\n",
    "        decode_length : 25\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Вы просто выбираете колонны из случайной колонки , выбрав случайной колонны , вы просто выбираете Котхарактеры .<EOS><pad>'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoders['targets'].decode(kek[0][0][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(model.sentence_cache.Flush())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "kek = sess.run([fast_result], feed_dict={\n",
    "        features_true['inputs'] : box_hpaulj(fake_inp[0:1]).reshape(1, -1, 1, 1),\n",
    "        features_true['targets'] : box_hpaulj(fake_inp[0:1]).reshape(1, -1, 1, 1),\n",
    "        decode_length : 25\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Как вы выбираете матрицу матрицу спутне?<EOS>'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoders['targets'].decode(kek[0][0][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "kek = sess.run([fast_result], feed_dict={\n",
    "        features_true['inputs'] : box_hpaulj(fake_inp[1:2]).reshape(1, -1, 1, 1),\n",
    "        features_true['targets'] : box_hpaulj(fake_inp[0:1]).reshape(1, -1, 1, 1),\n",
    "        decode_length : 25\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Вы просто выбирайте слова , что в теле по случайносттратить округа по ходит по ходит по обойти обойти округих обойти обойти обойти обойти обойти обойти обойти обойти'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoders['targets'].decode(kek[0][0][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders['inputs'].decode(targets[5][:-1].squeeze(1).squeeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders['targets'].decode(kek[1][23][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders['targets'].decode(targets[i][:-1].squeeze(1).squeeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "flusher = 0\n",
    "with open('/workspace/MT/transformer_cache_test_ru.dst', 'w', encoding='utf8') as file:\n",
    "    for it in data:\n",
    "        inputs = np.array(it['inputs']).reshape((1, len(it['inputs']), 1, 1))\n",
    "        targets = np.array(it['targets']).reshape((1, len(it['targets']), 1, 1))\n",
    "        kek = sess.run([fast_result], feed_dict={\n",
    "            features_true['inputs'] : inputs,\n",
    "            features_true['targets'] : targets,\n",
    "            decode_length : len(targets)\n",
    "        })\n",
    "        string = encoders['targets'].decode(np.squeeze(kek[0])[:-1])\n",
    "        print(string, file=file)\n",
    "        counter += 1\n",
    "        flusher += 1\n",
    "        if flusher == 5:\n",
    "            model.sentence_cache.Flush()\n",
    "            flusher = 0\n",
    "        if counter == 5000:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "with open('/workspace/MT/shad_nlp18_contextNMT/data_fused/en_test.src', 'r', encoding='utf8') as file:\n",
    "    with open('/workspace/MT/shad_nlp18_contextNMT/data_fused/en_test_short.src', 'w', encoding='utf8') as wfile:\n",
    "        for line in file:\n",
    "            print(line, file=wfile)\n",
    "            counter += 1\n",
    "            if counter == 5000:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "with open('/workspace/MT/shad_nlp18_contextNMT/data_fused/ru_test.dst', 'r', encoding='utf8') as file:\n",
    "    with open('/workspace/MT/shad_nlp18_contextNMT/data_fused/ru_test_short.dst', 'w', encoding='utf8') as wfile:\n",
    "        for line in file:\n",
    "            print(line, end='', file=wfile)\n",
    "            counter += 1\n",
    "            if counter == 5000:\n",
    "                break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
