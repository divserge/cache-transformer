{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.contrib.lookup import MutableHashTable\n",
    "from tensor2tensor.layers import common_layers\n",
    "\n",
    "from tensor2tensor.models import transformer\n",
    "sys.path.append('/workspace/MT/tensor2tensor/tensor2tensor/models/')\n",
    "sys.path.append('/workspace/MT/tensor2tensor/tensor2tensor/utils/')\n",
    "\n",
    "from transformer_test import TransformerTest\n",
    "from transformer_cache import TransformerCache\n",
    "from tensor2tensor.data_generators import problem_hparams\n",
    "from tensor2tensor.data_generators import problem\n",
    "\n",
    "sys.path.append('/workspace/MT/t2t_data_generators/')\n",
    "\n",
    "from generator import ShadENRUOpusProblem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=4\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found vocab file: /workspace/MT/shad_nlp18_contextNMT/data_4prev/vocab_enru.src\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-26 10:43:31,691] Found vocab file: /workspace/MT/shad_nlp18_contextNMT/data_4prev/vocab_enru.src\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found vocab file: /workspace/MT/shad_nlp18_contextNMT/data_4prev/vocab_enru.dst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-26 10:43:31,772] Found vocab file: /workspace/MT/shad_nlp18_contextNMT/data_4prev/vocab_enru.dst\n"
     ]
    }
   ],
   "source": [
    "shad_problem = ShadENRUOpusProblem()\n",
    "\n",
    "data = shad_problem.generate_encoded_samples(\n",
    "    '/workspace/MT/shad_nlp18_contextNMT/data_4prev/',\n",
    "    '/workspace/MT/shad_nlp18_contextNMT/data_4prev/',\n",
    "    problem.DatasetSplit.TEST\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_input = True\n",
    "mode=tf.estimator.ModeKeys.EVAL\n",
    "\n",
    "hparams = transformer.transformer_base_single_gpu()\n",
    "hparams.data_dir =  '/workspace/MT/shad_nlp18_contextNMT/data_4prev//'\n",
    "p_hparams = shad_problem.get_hparams(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams.batch_size = 1\n",
    "hparams.use_cache = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Unsetting shared_embedding_and_softmax_weights.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-26 10:43:32,191] Unsetting shared_embedding_and_softmax_weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-26 10:43:32,219] Setting T2TModel mode to 'eval'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-26 10:43:32,221] Setting hparams.relu_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-26 10:43:32,222] Setting hparams.attention_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-26 10:43:32,223] Setting hparams.dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-26 10:43:32,224] Setting hparams.symbol_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-26 10:43:32,226] Setting hparams.layer_prepostprocess_dropout to 0.0\n"
     ]
    }
   ],
   "source": [
    "model = TransformerCache(hparams, mode, p_hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_true = {\n",
    "    \"inputs\": tf.placeholder(shape=[None, None, 1, 1], dtype=tf.int32, name=\"inputs\"),\n",
    "    \"targets\": tf.placeholder(shape=[None, None, 1, 1], dtype=tf.int32, name=\"inputs\"),\n",
    "    \"target_space_id\": tf.constant(1, dtype=tf.int32)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found vocab file: /workspace/MT/shad_nlp18_contextNMT/data_4prev/vocab_enru.src\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-26 10:43:32,297] Found vocab file: /workspace/MT/shad_nlp18_contextNMT/data_4prev/vocab_enru.src\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found vocab file: /workspace/MT/shad_nlp18_contextNMT/data_4prev/vocab_enru.dst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-26 10:43:32,433] Found vocab file: /workspace/MT/shad_nlp18_contextNMT/data_4prev/vocab_enru.dst\n"
     ]
    }
   ],
   "source": [
    "data = shad_problem.generate_encoded_samples(\n",
    "    '/workspace/MT/shad_nlp18_contextNMT/data_4prev/',\n",
    "    '/workspace/MT/shad_nlp18_contextNMT/data_4prev/',\n",
    "    problem.DatasetSplit.TEST\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_length = tf.placeholder(dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"transformer_cache/while/Identity:0\", shape=(), dtype=int32)\n",
      "KEK\n"
     ]
    }
   ],
   "source": [
    "fast_result = model._beam_decode(features_true, decode_length, beam_size=2, top_beams=1, alpha=1.0)[\"outputs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict = {\"/\".join([\"transformer\"] + var.name[:-2].split('/')[1:]) : var for var in tf.global_variables()[5:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(save_dict)\n",
    "ckpt = tf.train.get_checkpoint_state('/workspace/MT/train/transformer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /workspace/MT/train/transformer/model.ckpt-250000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-26 10:43:44,544] Restoring parameters from /workspace/MT/train/transformer/model.ckpt-250000\n"
     ]
    }
   ],
   "source": [
    "if ckpt and ckpt.model_checkpoint_path:\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "else:\n",
    "    print(\"...no checkpoint found...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_saver = tf.train.Saver(tf.global_variables()[2:4])\n",
    "new_ckpt = tf.train.get_checkpoint_state('/workspace/MT/train_cache/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.tools.inspect_checkpoint import print_tensors_in_checkpoint_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_name:  sentence_level_cache/m_weight\n",
      "[[-0.0662327  -0.03821926 -0.01203594 ...,  0.01267674 -0.06697603\n",
      "  -0.00703066]\n",
      " [ 0.06985063 -0.06531873  0.053579   ..., -0.04061517  0.04970364\n",
      "  -0.03511227]\n",
      " [-0.01632818  0.0105549   0.00983872 ..., -0.05448194 -0.00812256\n",
      "   0.0255211 ]\n",
      " ..., \n",
      " [-0.03303513  0.02034533 -0.01472183 ..., -0.03932308 -0.0053694\n",
      "  -0.03564095]\n",
      " [ 0.04379536 -0.07470047  0.03121056 ...,  0.02519272  0.05219584\n",
      "  -0.03582729]\n",
      " [ 0.01609153 -0.00867114  0.02021801 ..., -0.041036    0.02171655\n",
      "  -0.03784646]]\n",
      "tensor_name:  sentence_level_cache/s_weight\n",
      "[[-0.30897236 -0.0865991  -0.04653369 ..., -0.09849302 -0.08101944\n",
      "  -0.0917303 ]\n",
      " [-0.03588444 -0.11626038 -0.04050927 ..., -0.03733981 -0.03060537\n",
      "  -0.03144538]\n",
      " [-0.04808292 -0.03741568 -0.25722969 ..., -0.04486312 -0.06077321\n",
      "  -0.0150316 ]\n",
      " ..., \n",
      " [-0.03111542 -0.04330374 -0.04637462 ...,  0.07261162 -0.03328684\n",
      "  -0.05452815]\n",
      " [-0.05466266 -0.06009268 -0.04546668 ..., -0.06550934 -0.01551719\n",
      "  -0.03463211]\n",
      " [-0.03396906 -0.03084998 -0.0397594  ..., -0.04909466 -0.0338569\n",
      "  -0.15093538]]\n"
     ]
    }
   ],
   "source": [
    "print_tensors_in_checkpoint_file(file_name=new_ckpt.model_checkpoint_path, tensor_name='',all_tensors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /workspace/MT/train_cache/transformer_cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-26 10:43:45,105] Restoring parameters from /workspace/MT/train_cache/transformer_cache\n"
     ]
    }
   ],
   "source": [
    "if new_ckpt and new_ckpt.model_checkpoint_path:\n",
    "    new_saver.restore(sess, new_ckpt.model_checkpoint_path)\n",
    "else:\n",
    "    print(\"...no checkpoint found...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders = shad_problem.feature_encoders('/workspace/MT/shad_nlp18_contextNMT/data_4prev/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import zip_longest\n",
    "\n",
    "def box_hpaulj(LoL):\n",
    "    return np.array(list(zip_longest(*LoL, fillvalue=0)), dtype=np.int32).T\n",
    "\n",
    "def batch_iterator(data, batch_size, context_size, n_steps=1000):\n",
    "    \n",
    "    for k in range(n_steps):\n",
    "        \n",
    "        batch_list_inp = [[] for _ in range(context_size)]\n",
    "        batch_list_targ = [[] for _ in range(context_size)]\n",
    "\n",
    "        for batch_i in range(batch_size):\n",
    "            for context_i, p in enumerate(data):\n",
    "                batch_list_inp[context_i].append(p['inputs'])\n",
    "                batch_list_targ[context_i].append(p['targets'])\n",
    "                if context_i == context_size - 1:\n",
    "                    break\n",
    "\n",
    "        for b_inp, b_out in zip(batch_list_inp, batch_list_targ):\n",
    "            yield {'inputs' : box_hpaulj(b_inp), 'targets' : box_hpaulj(b_out)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found vocab file: /workspace/MT/shad_nlp18_contextNMT/data_4prev/vocab_enru.src\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-26 10:43:45,794] Found vocab file: /workspace/MT/shad_nlp18_contextNMT/data_4prev/vocab_enru.src\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found vocab file: /workspace/MT/shad_nlp18_contextNMT/data_4prev/vocab_enru.dst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-26 10:43:45,922] Found vocab file: /workspace/MT/shad_nlp18_contextNMT/data_4prev/vocab_enru.dst\n"
     ]
    }
   ],
   "source": [
    "data = shad_problem.generate_encoded_samples(\n",
    "    '/workspace/MT/shad_nlp18_contextNMT/data_4prev/',\n",
    "    '/workspace/MT/shad_nlp18_contextNMT/data_4prev/',\n",
    "    problem.DatasetSplit.TEST,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "flusher = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in batch_iterator(data, hparams.batch_size, 5, n_steps=10000):\n",
    "    \n",
    "    inputs = it['inputs'].reshape((it['inputs'].shape[0], it['inputs'].shape[1], 1, 1))\n",
    "    targets = it['targets'].reshape((it['targets'].shape[0], it['targets'].shape[1], 1, 1))\n",
    "    break\n",
    "    kek = sess.run([fast_result], feed_dict={\n",
    "        features_true['inputs'] : inputs,\n",
    "        features_true['targets'] : targets,\n",
    "        decode_length : 25\n",
    "    })\n",
    "    \n",
    "    with open('/workspace/MT/transformer_cache_pred_ru.dst', 'a', encoding='utf8') as file_pred:\n",
    "        with open('/workspace/MT/transformer_cache_true_ru.dst', 'a', encoding='utf8') as file_true:\n",
    "            for seq_i in range(hparams.batch_size):\n",
    "                pred = encoders['targets'].decode(kek[0][seq_i][:-1])\n",
    "                true = encoders['targets'].decode(targets[seq_i][:-1].squeeze(1).squeeze(1))\n",
    "                print(''.join(pred.split('<EOS>')[0]), file=file_pred)\n",
    "                print(''.join(true.split('<EOS>')[0]), file=file_true)\n",
    "                \n",
    "    counter += 1\n",
    "    flusher += 1\n",
    "    \n",
    "    if flusher == 5:\n",
    "        sess.run(model.sentence_cache.Flush())\n",
    "        flusher = 0\n",
    "    \n",
    "    if counter == 60:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = [\n",
    "    'How do you choose the matrix columns?',\n",
    "    'You just choose the columns at random',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_inp = [encoders['inputs'].encode(t) for t in inp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[122, 39, 6, 1263, 8, 4670, 15341, 22026, 21995],\n",
       " [16, 44, 1263, 8, 15341, 63, 4573]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  122,    39,     6,  1263,     8,  4670, 15341, 22026, 21995]], dtype=int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box_hpaulj(fake_inp[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(model.sentence_cache.Flush())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "kek = sess.run([fast_result], feed_dict={\n",
    "        features_true['inputs'] : box_hpaulj(fake_inp[0:1]).reshape(1, -1, 1, 1),\n",
    "        features_true['targets'] : box_hpaulj(fake_inp[0:1]).reshape(1, -1, 1, 1),\n",
    "        decode_length : 25\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Как вы можете выбирать климатрицы матрицы?<EOS><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoders['targets'].decode(kek[0][0][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "kek = sess.run([fast_result], feed_dict={\n",
    "        features_true['inputs'] : box_hpaulj(fake_inp[1:2]).reshape(1, -1, 1, 1),\n",
    "        features_true['targets'] : box_hpaulj(fake_inp[0:1]).reshape(1, -1, 1, 1),\n",
    "        decode_length : 25\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Вы просто выбираете колонны из случайной колонки , выбрав случайной колонны , вы просто выбираете Котхарактеры .<EOS><pad>'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoders['targets'].decode(kek[0][0][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(model.sentence_cache.Flush())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "kek = sess.run([fast_result], feed_dict={\n",
    "        features_true['inputs'] : box_hpaulj(fake_inp[0:1]).reshape(1, -1, 1, 1),\n",
    "        features_true['targets'] : box_hpaulj(fake_inp[0:1]).reshape(1, -1, 1, 1),\n",
    "        decode_length : 25\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Как вы выбираете матрицу матрицу спутне?<EOS>'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoders['targets'].decode(kek[0][0][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "kek = sess.run([fast_result], feed_dict={\n",
    "        features_true['inputs'] : box_hpaulj(fake_inp[1:2]).reshape(1, -1, 1, 1),\n",
    "        features_true['targets'] : box_hpaulj(fake_inp[0:1]).reshape(1, -1, 1, 1),\n",
    "        decode_length : 25\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Вы просто выбирайте слова , что в теле по случайносттратить округа по ходит по ходит по обойти обойти округих обойти обойти обойти обойти обойти обойти обойти обойти'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoders['targets'].decode(kek[0][0][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders['inputs'].decode(targets[5][:-1].squeeze(1).squeeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders['targets'].decode(kek[1][23][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders['targets'].decode(targets[i][:-1].squeeze(1).squeeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "flusher = 0\n",
    "with open('/workspace/MT/transformer_cache_test_ru.dst', 'w', encoding='utf8') as file:\n",
    "    for it in data:\n",
    "        inputs = np.array(it['inputs']).reshape((1, len(it['inputs']), 1, 1))\n",
    "        targets = np.array(it['targets']).reshape((1, len(it['targets']), 1, 1))\n",
    "        kek = sess.run([fast_result], feed_dict={\n",
    "            features_true['inputs'] : inputs,\n",
    "            features_true['targets'] : targets,\n",
    "            decode_length : len(targets)\n",
    "        })\n",
    "        string = encoders['targets'].decode(np.squeeze(kek[0])[:-1])\n",
    "        print(string, file=file)\n",
    "        counter += 1\n",
    "        flusher += 1\n",
    "        if flusher == 5:\n",
    "            model.sentence_cache.Flush()\n",
    "            flusher = 0\n",
    "        if counter == 5000:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "with open('/workspace/MT/shad_nlp18_contextNMT/data_fused/en_test.src', 'r', encoding='utf8') as file:\n",
    "    with open('/workspace/MT/shad_nlp18_contextNMT/data_fused/en_test_short.src', 'w', encoding='utf8') as wfile:\n",
    "        for line in file:\n",
    "            print(line, file=wfile)\n",
    "            counter += 1\n",
    "            if counter == 5000:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "with open('/workspace/MT/shad_nlp18_contextNMT/data_fused/ru_test.dst', 'r', encoding='utf8') as file:\n",
    "    with open('/workspace/MT/shad_nlp18_contextNMT/data_fused/ru_test_short.dst', 'w', encoding='utf8') as wfile:\n",
    "        for line in file:\n",
    "            print(line, end='', file=wfile)\n",
    "            counter += 1\n",
    "            if counter == 5000:\n",
    "                break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
